{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Laxmi\n",
        "\n",
        "\n",
        "Week 9 Assignment - Scikit Learn"
      ],
      "metadata": {
        "id": "VRwfl1qvT4tN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1\n",
        "\n",
        "\n",
        "The basic logistic regression model with liblinear solver represents the optimal solution because it delivers both high accuracy and fast computational time. The training accuracy reached 0.7333 while test accuracy was 0.718 for this model that shows reliability and resistance to overfitting problems. The basic logistic regression model with liblinear solver runs quickly while delivering satisfactory results without requiring advanced hyperparameter adjustments or large computational power.\n",
        "\n",
        "The evaluation of different models involved multiple logistic regression models with L1 regularization (LASSO) that used various C values for testing. The test accuracy reached 0.718 when C was set to 10 and matched the performance of the unregularized basic logistic regression model. The addition of L1 penalty regularization failed to enhance performance metrics on this particular dataset. The best C value discovered through cross-validation for LogisticRegressionCV was 0.0886 yet it produced a test accuracy of 0.708 which was slightly worse than the previous results.\n",
        "\n",
        "The combination of scaling and pipelines (Logistic_SL1_C_auto) resulted in a minimal improvement to test accuracy which reached 0.714. The data relationships appear straightforward because the addition of polynomial features along with LASSO regularization failed to enhance performance.\n",
        "\n",
        "RandomForest_noCV achieved superb training performance with 0.9993 accuracy while delivering poor test result accuracy at 0.686. The significant difference between training and testing accuracy demonstrates that the model has overfitted the training data excessively which prevents it from working with new test data.\n",
        "\n",
        "The application of cross-validation (RandomForest_CV) to random forest model optimization delivered marginal performance enhancement yet the test accuracy stayed inferior to logistic regression models. The results from grid search optimization of hyperparameters including number of trees, maximum features and maximum tree depth showed no significant performance enhancement.\n",
        "\n",
        "The basic logistic regression model with liblinear solver demonstrated optimal performance by achieving a good combination of accuracy and computational efficiency. The test results showed that the random forest model failed despite achieving excellent training performance which indicates that it experienced overfitting. The basic logistic regression model proved to be superior to all regularized logistic regression models and their variants for this dataset.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FmF28CPZVCkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2 and 3"
      ],
      "metadata": {
        "id": "CZmbDIJrVNme"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ghBlfn39TMEa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "healthcare_data = pd.read_csv('./PatientAnalyticFile.csv')\n",
        "healthcare_data['mortality'] = np.where(healthcare_data['DateOfDeath'].isnull(), 0, 1)\n",
        "\n",
        "#DateOfBirth to datetime and calculate age\n",
        "healthcare_data['DateOfBirth'] = pd.to_datetime(healthcare_data['DateOfBirth'])\n",
        "healthcare_data['Age_years'] = ((pd.to_datetime('2015-01-01') - healthcare_data['DateOfBirth']).dt.days / 365.25)\n",
        "\n",
        "#Drop unnecessary columns\n",
        "columns_to_drop = ['PatientID', 'First_Appointment_Date', 'DateOfBirth', 'Last_Appointment_Date', 'DateOfDeath']\n",
        "healthcare_data_clean = healthcare_data.drop(columns=columns_to_drop)\n",
        "\n",
        "#Convert categorical variables to dummy variables\n",
        "healthcare_data_clean = pd.get_dummies(healthcare_data_clean, drop_first=True)"
      ],
      "metadata": {
        "id": "QivvBlzmVVhg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = healthcare_data_clean.drop('mortality', axis=1)\n",
        "y = healthcare_data_clean['mortality']\n",
        "\n",
        "#Spliting the data into training and holdout sets (80% train, 20% test)\n",
        "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "rJIyedzBVaTo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solvers = ['liblinear', 'lbfgs', 'newton-cg', 'sag', 'saga']\n",
        "results = []"
      ],
      "metadata": {
        "id": "BLgH9RcqVcDT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for solver in solvers:\n",
        "    try:\n",
        "        model = LogisticRegression(solver=solver, max_iter=500)\n",
        "        start_time = time.time()\n",
        "        model.fit(X_train, y_train)\n",
        "        end_time = time.time()\n",
        "        training_time = end_time - start_time\n",
        "        train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
        "        holdout_accuracy = accuracy_score(y_holdout, model.predict(X_holdout))\n",
        "        results.append([solver, train_accuracy, holdout_accuracy, training_time])\n",
        "    except Exception as e:\n",
        "        results.append([solver, \"Error\", \"Error\", str(e)])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=['Solver', 'Training Accuracy', 'Holdout Accuracy', 'Time Taken (seconds)'])\n",
        "\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5z27Cnk6Vd3C",
        "outputId": "ddfc0529-da3a-44cb-b319-7e149b1a394d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Solver  Training Accuracy  Holdout Accuracy  Time Taken (seconds)\n",
            "0  liblinear           0.748125           0.73625              0.224812\n",
            "1      lbfgs           0.748125           0.73600              1.436774\n",
            "2  newton-cg           0.748062           0.73575              0.489363\n",
            "3        sag           0.748125           0.73625             12.927828\n",
            "4       saga           0.748125           0.73600             11.195167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the results, which solver yielded the best results? Explain the basis for ranking the models - did you use training subset accuracy? Holdout subset accuracy? Time of execution? All three? Some combination of the three?\n",
        "\n",
        "\n",
        "The accuracy scores from all solvers including liblinear, lbfgs, newton-cg, sag, and saga matched each other on both training and holdout subsets. The training accuracy remains stable at 0.748 but the holdout accuracy stays at 0.736. The solvers create equivalent models which demonstrate the same level of generalization for new data points.\n",
        "\n",
        "Model assessment requires examination of both accuracy results and training duration. Time computation plays a decisive role for assessing model generalization ability fundamentally through accuracy metrics because of its significance in operation with big datasets and real-time prediction processes. The sag and saga solvers needed substantially longer to finish training than other solvers with times of **12.93 seconds** and **11.20 seconds** respectively. The longer training time of these solvers reduces their value compared to alternative faster solutions.\n",
        "\n",
        "The liblinear solver reached a holdout accuracy of 0.73625 while completing the process in just 0.22 seconds which makes it the fastest among all other solvers. The newton-cg solver achieved similar accuracy to other solvers yet required **0.49 seconds** to execute. The lbfgs solver achieved comparable results to the other solvers while requiring **1.44 seconds** to finish its computation. This makes it faster than sag and saga but slower than liblinear.\n",
        "\n",
        "The best solver according to all three criteria of training accuracy and holdout accuracy and training duration is **liblinear**. The solver provides both high accuracy and short computation time to achieve the best results on the holdout subset. The solver offers the optimal combination of accuracy and computational speed which makes it the most appropriate solver for this dataset and problem."
      ],
      "metadata": {
        "id": "8DGGLjwyVuer"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dbwhkWL6Vt7N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}