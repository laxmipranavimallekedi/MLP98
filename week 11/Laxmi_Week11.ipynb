{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F_6Q10Vkhr5",
        "outputId": "bef6faca-9212-438c-fb5a-cc1b3d4f99e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model with dataset size: 100\n",
            "  Test accuracy: 0.9064\n",
            "  CV score: 0.8900 ± 0.0374\n",
            "  Fit time: 0.03 seconds\n",
            "  CV time: 0.22 seconds\n",
            "\n",
            "Evaluating model with dataset size: 1000\n",
            "  Test accuracy: 0.9525\n",
            "  CV score: 0.9400 ± 0.0164\n",
            "  Fit time: 0.07 seconds\n",
            "  CV time: 0.38 seconds\n",
            "\n",
            "Evaluating model with dataset size: 10000\n",
            "  Test accuracy: 0.9713\n",
            "  CV score: 0.9735 ± 0.0023\n",
            "  Fit time: 0.16 seconds\n",
            "  CV time: 0.80 seconds\n",
            "\n",
            "Evaluating model with dataset size: 100000\n",
            "  Test accuracy: 0.9826\n",
            "  CV score: 0.9822 ± 0.0009\n",
            "  Fit time: 1.64 seconds\n",
            "  CV time: 3.45 seconds\n",
            "\n",
            "Evaluating model with dataset size: 1000000\n",
            "  Test accuracy: 0.9846\n",
            "  CV score: 0.9846 ± 0.0003\n",
            "  Fit time: 9.51 seconds\n",
            "  CV time: 39.41 seconds\n",
            "\n",
            "      size  test_accuracy  cv_score  fit_time    cv_time\n",
            "0      100       0.906384  0.890000  0.031617   0.220047\n",
            "1     1000       0.952546  0.940000  0.065960   0.376083\n",
            "2    10000       0.971261  0.973500  0.157059   0.804156\n",
            "3   100000       0.982619  0.982180  1.635043   3.452670\n",
            "4  1000000       0.984622  0.984621  9.506023  39.412236\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"dfdataWeek11.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('outcome', axis=1)\n",
        "y = data['outcome']\n",
        "\n",
        "# Split data for final evaluation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create different dataset sizes\n",
        "sizes = [100, 1000, 10000, 100000, 1000000]\n",
        "results = []\n",
        "\n",
        "# Function to sample dataset and evaluate\n",
        "def evaluate_model(size):\n",
        "    # Check if we have enough data for the requested size\n",
        "    if size > len(X_train):\n",
        "        print(f\"Not enough data for size {size}, using all available data: {len(X_train)}\")\n",
        "        X_sample = X_train\n",
        "        y_sample = y_train\n",
        "    else:\n",
        "        # Sample the data\n",
        "        indices = np.random.choice(len(X_train), size, replace=False)\n",
        "        X_sample = X_train.iloc[indices]\n",
        "        y_sample = y_train.iloc[indices]\n",
        "\n",
        "    # Create and configure the model\n",
        "    model = XGBClassifier(\n",
        "        learning_rate=0.1,\n",
        "        n_estimators=100,\n",
        "        max_depth=5,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Measure cross-validation time and score\n",
        "    start_time = time.time()\n",
        "    cv_scores = cross_val_score(model, X_sample, y_sample, cv=5, scoring='accuracy')\n",
        "    cv_time = time.time() - start_time\n",
        "\n",
        "    # Fit the model on the full sample\n",
        "    start_time = time.time()\n",
        "    model.fit(X_sample, y_sample)\n",
        "    fit_time = time.time() - start_time\n",
        "\n",
        "    # Evaluate on test set\n",
        "    y_pred = model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return {\n",
        "        'size': size,\n",
        "        'cv_score': cv_scores.mean(),\n",
        "        'cv_std': cv_scores.std(),\n",
        "        'test_accuracy': test_accuracy,\n",
        "        'fit_time': fit_time,\n",
        "        'cv_time': cv_time,\n",
        "        'sample_size': len(X_sample)\n",
        "    }\n",
        "\n",
        "# Run evaluation for each size\n",
        "for size in sizes:\n",
        "    if size > 100000000:  # Skip very large sizes unless necessary\n",
        "        print(f\"Size {size} is very large, skipping. Remove this check if you want to run it.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Evaluating model with dataset size: {size}\")\n",
        "    result = evaluate_model(size)\n",
        "    results.append(result)\n",
        "    print(f\"  Test accuracy: {result['test_accuracy']:.4f}\")\n",
        "    print(f\"  CV score: {result['cv_score']:.4f} ± {result['cv_std']:.4f}\")\n",
        "    print(f\"  Fit time: {result['fit_time']:.2f} seconds\")\n",
        "    print(f\"  CV time: {result['cv_time']:.2f} seconds\")\n",
        "    print()\n",
        "\n",
        "# Create a table with results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df[['size', 'test_accuracy', 'cv_score', 'fit_time', 'cv_time']])"
      ]
    }
  ]
}